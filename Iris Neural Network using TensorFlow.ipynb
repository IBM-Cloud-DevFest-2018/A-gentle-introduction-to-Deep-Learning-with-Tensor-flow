{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Dependencies\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Make results reproducible\nseed = 1234\nnp.random.seed(seed)\ntf.set_random_seed(seed)"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0   1            5.1           3.5            1.4           0.2  Iris-setosa\n1   2            4.9           3.0            1.4           0.2  Iris-setosa\n2   3            4.7           3.2            1.3           0.2  Iris-setosa\n3   4            4.6           3.1            1.5           0.2  Iris-setosa\n4   5            5.0           3.6            1.4           0.2  Iris-setosa"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_data_1 = pd.get_dummies(df_data_1, columns=['Species']) # One Hot Encoding\nvalues = list(df_data_1.columns.values)"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y = df_data_1[values[-3:]]\ny = np.array(y, dtype='float32')\nX = df_data_1[values[1:-3]]\nX = np.array(X, dtype='float32')"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Shuffle Data\nindices = np.random.choice(len(X), len(X), replace=False)\nX_values = X[indices]\ny_values = y[indices]"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Creating a Train and a Test Dataset\ntest_size = 10\nX_test = X_values[-test_size:]\nX_train = X_values[:-test_size]\ny_test = y_values[-test_size:]\ny_train = y_values[:-test_size]"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Session\nsess = tf.Session()"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Interval / Epochs\ninterval = 50\nepoch = 500"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Initialize placeholders\nX_data = tf.placeholder(shape=[None, 4], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 3], dtype=tf.float32)"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Input neurons : 4\n# Hidden neurons : 8\n# Output neurons : 3\nhidden_layer_nodes = 8"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Create variables for Neural Network layers\nw1 = tf.Variable(tf.random_normal(shape=[4,hidden_layer_nodes])) # Inputs -> Hidden Layer\nb1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes]))   # First Bias\nw2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes,3])) # Hidden layer -> Outputs\nb2 = tf.Variable(tf.random_normal(shape=[3]))   # Second Bias"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Operations\nhidden_output = tf.nn.relu(tf.add(tf.matmul(X_data, w1), b1))\nfinal_output = tf.nn.softmax(tf.add(tf.matmul(hidden_output, w2), b2))"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Cost Function\nloss = tf.reduce_mean(-tf.reduce_sum(y_target * tf.log(final_output), axis=0))"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Initialize variables\ninit = tf.global_variables_initializer()\nsess.run(init)"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Training the model...\nEpoch 50 | Loss: 26.0493\nEpoch 100 | Loss: 13.5538\nEpoch 150 | Loss: 9.70475\nEpoch 200 | Loss: 7.4782\nEpoch 250 | Loss: 6.32777\nEpoch 300 | Loss: 5.57709\nEpoch 350 | Loss: 5.05237\nEpoch 400 | Loss: 4.66673\nEpoch 450 | Loss: 4.35809\nEpoch 500 | Loss: 4.0857\n"
                }
            ], 
            "source": "# Training\nprint('Training the model...')\nfor i in range(1, (epoch + 1)):\n    sess.run(optimizer, feed_dict={X_data: X_train, y_target: y_train})\n    if i % interval == 0:\n        print('Epoch', i, '|', 'Loss:', sess.run(loss, feed_dict={X_data: X_train, y_target: y_train}))"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nActual: [ 0.  0.  1.] Predicted: [[ 0.  0.  1.]]\nActual: [ 1.  0.  0.] Predicted: [[ 1.  0.  0.]]\nActual: [ 0.  0.  1.] Predicted: [[ 0.  0.  1.]]\nActual: [ 1.  0.  0.] Predicted: [[ 1.  0.  0.]]\nActual: [ 1.  0.  0.] Predicted: [[ 1.  0.  0.]]\nActual: [ 0.  0.  1.] Predicted: [[ 0.  0.  1.]]\nActual: [ 0.  0.  1.] Predicted: [[ 0.  0.  1.]]\nActual: [ 0.  1.  0.] Predicted: [[ 0.  1.  0.]]\nActual: [ 1.  0.  0.] Predicted: [[ 1.  0.  0.]]\nActual: [ 1.  0.  0.] Predicted: [[ 1.  0.  0.]]\n"
                }
            ], 
            "source": "# Prediction\nprint()\nfor i in range(len(X_test)):\n    print('Actual:', y_test[i], 'Predicted:', np.rint(sess.run(final_output, feed_dict={X_data: [X_test[i]]})))"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}